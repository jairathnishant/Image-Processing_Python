{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jairathnishant/Image-Processing_Python/blob/main/Cancer_detection_EfficientNetB7_model_(Histopathology).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580a9635",
      "metadata": {
        "id": "580a9635"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7  as PretrainedModel, preprocess_input\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "M_OS9RUIZQA1"
      },
      "id": "M_OS9RUIZQA1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "HwhISQoHaEpF"
      },
      "id": "HwhISQoHaEpF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/lung-and-colon-cancer-histopathological-images"
      ],
      "metadata": {
        "id": "nlS7IXBzZuYd"
      },
      "id": "nlS7IXBzZuYd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('lung-and-colon-cancer-histopathological-images.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "HJpGrFJ4d0zA"
      },
      "id": "HJpGrFJ4d0zA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48de461",
      "metadata": {
        "id": "d48de461"
      },
      "outputs": [],
      "source": [
        "folders = os.listdir('/tmp/lung_colon_image_set/lung_image_sets')\n",
        "# glob(r'C:\\Users\\nishantjairath\\Downloads\\lung_image_sets' + '\\*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e6f46d",
      "metadata": {
        "id": "56e6f46d"
      },
      "outputs": [],
      "source": [
        "path = (r'/tmp/lung_colon_image_set/lung_image_sets')\n",
        "classes = os.listdir(path)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_FILES = glob(r'/tmp/lung_colon_image_set/lung_image_sets' + '/*/*.jpeg')\n",
        "print('Images Count: ', len(IMAGE_FILES))"
      ],
      "metadata": {
        "id": "1UbO05nBfJdQ"
      },
      "id": "1UbO05nBfJdQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05fdb02f",
      "metadata": {
        "id": "05fdb02f"
      },
      "outputs": [],
      "source": [
        "for cat in classes:\n",
        "    image_dir = f'{path}/{cat}'\n",
        "    images = os.listdir(image_dir)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "    fig.suptitle(f'Images for {cat} category...', fontsize = 20)\n",
        "    \n",
        "    for i in range(3):\n",
        "        k = np.random.randint(0, len(images))\n",
        "        img = np.array(Image.open(f'{path}/{cat}/{images[k]}'))\n",
        "        ax[i].imshow(img)\n",
        "        ax[i].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fddf761",
      "metadata": {
        "id": "8fddf761"
      },
      "outputs": [],
      "source": [
        "data_dir = '/tmp/lung_colon_image_set/lung_image_sets'\n",
        "\n",
        "# 80-20 Split\n",
        "data = ImageDataGenerator(validation_split = 0.2)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# 224 x 224 -- The minimum for EfficientNetB7, you can go as high as 600 x 600\n",
        "X = Y = 224\n",
        "\n",
        "train_ds = data.flow_from_directory(data_dir,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    target_size = (X, Y),\n",
        "                                    color_mode=\"rgb\",\n",
        "                                    batch_size = BATCH_SIZE, \n",
        "                                    shuffle = False,\n",
        "                                    subset='training',\n",
        "                                    seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04d1e33",
      "metadata": {
        "id": "e04d1e33"
      },
      "outputs": [],
      "source": [
        "validation = data.flow_from_directory(data_dir,\n",
        "                                      class_mode = \"categorical\",\n",
        "                                      target_size = (X, Y),\n",
        "                                      color_mode=\"rgb\",\n",
        "                                      batch_size = BATCH_SIZE, \n",
        "                                      shuffle = False,\n",
        "                                      subset='validation',\n",
        "                                      seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834c82b4",
      "metadata": {
        "id": "834c82b4"
      },
      "outputs": [],
      "source": [
        "ptm = PretrainedModel(\n",
        "    input_shape=(X, Y, 3),\n",
        "    weights='imagenet',\n",
        "    include_top=False)\n",
        "\n",
        "ptm.trainable = False\n",
        "\n",
        "K = len(folders)\n",
        "\n",
        "x = GlobalAveragePooling2D()(ptm.output)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "y = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=ptm.input, outputs=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066d8460",
      "metadata": {
        "id": "066d8460"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60af4ba",
      "metadata": {
        "id": "d60af4ba"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5981e349",
      "metadata": {
        "id": "5981e349"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "plot_model(model, to_file='NN-mnist.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc5aee7",
      "metadata": {
        "id": "1cc5aee7"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stopping])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}